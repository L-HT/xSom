% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{learnCyclesExtended}
\alias{learnCyclesExtended}
\title{A single SOM training step}
\usage{
learnCyclesExtended(dataSet, weightMatrix, oldColumns, cycles = 1L,
  initLearnRate = 0.01, learnRateReduction = 0, initRadius = 1,
  radiusReduction = -1, normType = 2L, sampling = 1L, naExist = TRUE,
  updateParametersPerEpoch = TRUE, currentTrainingStep = 0L)
}
\arguments{
\item{dataSet}{The data set.}

\item{weightMatrix}{The initial weight matrix (also known as codebook matrix). A possible
initialization is provided with the function \code{som.init.extended}. Note that the
weight matrix must have N rows where N is a squared number because this SOM algorithm
arranges the N codebook neurons in a two-dimensional quadratic grid.}

\item{oldColumns}{A boolean vector specifying the columns of the data set which were already
available before the data set has been extended. In other words, the SOM algorithm only
uses these columns for the calculation of Best Matching Units while the other other columns
are ignored during this step, but still modified during the update of the weight matrix
(codebook matrix).}

\item{cycles}{How many cycles (epochs) are used for this training step.}

\item{initLearnRate}{A vector with two numbers specifying the initial learn rate for the
two training steps. The default is \code{(0.05,0.02)}. If only one value \code{x} given, it will be
interpreted as \code{(x, x/2.0)}.
This is based on the \code{som} package written by Jun Yan.}

\item{learnRateReduction}{A number specifying how the radius for the gaussian neighborhood function
is reduced during each parameter update (see also \code{updateParametersPerEpoch}).}

\item{initRadius}{A vector with two numbers specifying the initial radii for the
gaussian neighborhood function during the two training steps.
The default is \code{(somSize,min(somSize,3))}, where somSize refers to the size of the
quadratic grid which is used for the codebook neurons (see the argument \code{weightMatrix}.
If only one value \code{x} given, it will be interpreted as \code{(x, max(x,2))}.
This is based on the \code{som} package written by Jun Yan.}

\item{radiusReduction}{A number specifying how the radius for the gaussian neighborhood function
is reduced during each parameter update (see also \code{updateParametersPerEpoch}).}

\item{normType}{This must be either 1 or 2. It specifies how the distance between neurons
in the quadratic grid is calculated. The value 1 uses the 1-norm (absolute value) and leads
to rectangular structures in the resulting SOM while the value 2 uses the 2-norm (root of the
sum of squares, also known as euclidian norm) which leads to circular structures.}

\item{sampling}{A non-negative integer specifying how the data set is run through during
a training cycle. The value 0 makes the algorithm run through the data set without any
changes. The value 1 makes it use a random order while any value K greater than 1
makes it randomly select K rows from the data sets (there it is possible that the
same row is selected multiple times)}

\item{naExist}{A boolean value indicating whether NAs are present. If the argument
\code{naExist} is set to \code{FALSE}, the first 100 lines of the data set will be
scanned for NA values. Depending on whether NA values are found slightly different
SOM algorithms are executed:
If NA values exist, the algorithm will ignore these values during the calculation of the
Best Matching Unit (BMU). If no NA values exist, this step is omitted which improves
the runtime of the algorithm.}

\item{updateParametersPerEpoch}{A boolean value specifying when the learning rate and the
radius are updated during the SOM training. If it is set to \code{TRUE}, the update is done
after the algorithm went through the data set (or the sampled rows if \code{sampling} > 1).
The \code{som} algorithm written bei Jun Yan updates the learn rate and radius after every row.
This behavior is replicated by setting \code{updateParametersPerEpoch} to \code{FALSE}.}

\item{currentTrainingStep}{This parameter is used to replicate the default behavior of the
SOM algorithm in the SOM package written by Jun Yan. The original algorithm executed
two training steps in succession while this function replicates the first or second
step depending on whether this parameter is set to 1 or 2. The default value is 0 (no change).}
}
\description{
This function corresponds to a single training step in the SOM algortihm.
}
\examples{
#generate Data
dataSet <- matrix(as.numeric(1:400),ncol=2)
weightMatrix <- som.init.extended(dataSet, somSize=3, oldColumns=c(TRUE,TRUE))

#apply the algorithm
result <- learnCyclesExtended(dataSet, weightMatrix,
     oldColumns=c(TRUE,TRUE), currentTrainingStep=1)
result <- learnCyclesExtended(dataSet, result,
     oldColumns=c(TRUE,TRUE),currentTrainingStep=2)
#result now contains the final result
}
